{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from datetime import datetime, date, time, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "raw_df = pd.read_csv('cleaned_urx_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# manipulation of data\n",
    "\n",
    "# dict of created times and ids\n",
    "created_at_dict = dict()\n",
    "for line in raw_df.groupby('_worker_id')['_created_at']:\n",
    "    created_at_dict[line[0]] = line[1]\n",
    "    \n",
    "# dict of started times and ids    \n",
    "started_at_dict = dict()\n",
    "for line in raw_df.groupby('_worker_id')['_started_at']:\n",
    "    started_at_dict[line[0]] = line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## manipulate data for analysis \n",
    "##\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## identify robots by too many posts\n",
    "##\n",
    "\n",
    "def too_many_jobs():\n",
    "    \n",
    "    \n",
    "    return too_many_jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## identify robots by too little variance\n",
    "##\n",
    "\n",
    "def too_little_variance():\n",
    "    \n",
    "    \n",
    "    return too_little_variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## identify robots by individual mean outside of the confidence interval for his/her job count\n",
    "##\n",
    "\n",
    "def mean_outside_ci():\n",
    "    \n",
    "    \n",
    "    return mean_outside_ci \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## identify robots by time stamp variability \n",
    "\n",
    "# takes a list of datetime strings and returns a list of datetime objects\n",
    "def make_list_datetime(list_of_time_strings):\n",
    "    date_time_list = []\n",
    "    for time in list_of_time_strings:\n",
    "        date_time_list.append(datetime.strptime(time, \"%m/%d/%Y %H:%M:%S\"))\n",
    "    return date_time_list\n",
    "\n",
    "\n",
    "# take in lists of creation, start datetime strings, output list of differences in seconds \n",
    "def creation_start_dif(creation_list, start_list):\n",
    "    # make all into datetime objects \n",
    "    creation_datetimes = make_list_datetime(creation_list)\n",
    "    start_datetimes = make_list_datetime(start_list)\n",
    "    \n",
    "    # iterate through to calculate each difference \n",
    "    creation_start_diffs = []\n",
    "    indexer = range(0,len(creation_datetimes))\n",
    "    for index in indexer:\n",
    "        diff = creation_datetimes[index] - start_datetimes[index]\n",
    "        creation_start_diffs.append(diff.total_seconds())    \n",
    "    return creation_start_diffs\n",
    "\n",
    "\n",
    "def too_little_timestamp_variability(created_dict, started_dict ):\n",
    "\n",
    "    # produce the list of differences for each worker \n",
    "    creation_time = created_dict.values()\n",
    "    started_time = started_dict.values()\n",
    "    \n",
    "    creation_start_diff_list = []\n",
    "    indexer = range(0,len(started_time))\n",
    "    for index in indexer:\n",
    "        diff_list = creation_start_dif(creation_time[index], started_time[index])\n",
    "        creation_start_diff_list.append(diff_list)\n",
    "    \n",
    "    # calculate the diversity measure\n",
    "    diversity_list = []\n",
    "\n",
    "    for ind_list in creation_start_diff_list:\n",
    "        uniques = len(set(ind_list)) + 0.0\n",
    "        diversity = uniques/len(ind_list)\n",
    "        diversity_list.append(diversity)\n",
    "    \n",
    "        \n",
    "    return diversity_list\n",
    "\n",
    "diversity_scores = too_little_timestamp_variability(created_at_dict, started_at_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'hist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-abb1ca40eefc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoo_little_timestamp_variability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_at_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarted_at_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'hist'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# manipulate data for evaluation of workers\n",
    "\n",
    "worker_mean = []\n",
    "worker_var = []\n",
    "worker_count = 0\n",
    "worker_job_count = []\n",
    "worker_list = []\n",
    "\n",
    "for worker in raw_df.groupby('_worker_id'):\n",
    "    worker_list.append(worker[0])\n",
    "    worker_mean.append(worker[1]['please_make_your_relevancy_judgment'].mean())\n",
    "    worker_var.append(worker[1]['please_make_your_relevancy_judgment'].var())\n",
    "    worker_job_count.append(worker[1]['please_make_your_relevancy_judgment'].count())\n",
    "    \n",
    "    worker_count += 1\n",
    "\n",
    "worker_count\n",
    "\n",
    "worker_var_dict = dict(zip(worker_list, worker_var))\n",
    "worker_count_dict = dict(zip(worker_list,worker_job_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#extract the information that i want from the dataframe object\n",
    "\n",
    "worker_ids = []\n",
    "unit_ids = []\n",
    "worker_scores = []\n",
    "event_id = []\n",
    "event_time_stamp = []\n",
    "start_time_stamp = []\n",
    "trust = []\n",
    "\n",
    "\n",
    "count = 0\n",
    "test_size = 100\n",
    "\n",
    "for row in raw_df.groupby('_worker_id'):\n",
    "    worker_ids.append(row[0])\n",
    "    unit_id.append(row[1]['_unit_id'])\n",
    "    worker_scores.append(row[1]['please_make_your_relevancy_judgment'])\n",
    "    event_id.append(row[1]['_id'])\n",
    "    trust.append(row[1].append)\n",
    "    event_time_stamp.append(row[1]['_started_at'])\n",
    "    start_time_stamp.append(row[1]['_created_at'])\n",
    "\n",
    "    \n",
    "    count += 1\n",
    "    if count == test_size:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make some aggregations into the objects with the more useful information paired up and so forth\n",
    "id_scores_dict = dict(zip(worker_ids, worker_scores))\n",
    "id_time_dict = dict(zip(worker_ids, event_time_stamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "event_df.hist(bins = 40, layout = (50,2), figsize = (6,100), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event_df.columns = worker_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time_stamp\n",
    "event_time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# takes a list of datetime strings and returns a list of datetime objects\n",
    "def make_list_datetime(list_of_time_strings):\n",
    "    date_time_list = []\n",
    "    for time in list_of_time_strings:\n",
    "        date_time_list.append(datetime.strptime(time, \"%m/%d/%Y %H:%M:%S\"))\n",
    "    return date_time_list\n",
    "print make_list_datetime(start_time_stamp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take in lists of creation, start datetime strings, output list of differences in seconds \n",
    "def creation_start_dif(creation_list, start_list):\n",
    "    # make all into datetime objects \n",
    "    creation_datetimes = make_list_datetime(creation_list)\n",
    "    start_datetimes = make_list_datetime(start_list)\n",
    "    \n",
    "    # iterate through to calculate each difference \n",
    "    creation_start_diffs = []\n",
    "    indexer = range(0,len(creation_datetimes))\n",
    "    for index in indexer:\n",
    "        diff = creation_datetimes[index] - start_datetimes[index]\n",
    "        creation_start_diffs.append(diff.total_seconds())    \n",
    "    return creation_start_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## how to fit a normal distribution to a histogram and do basic anomaly detection  \n",
    "diversity_series = pd.Series(data = diversity_list)\n",
    "\n",
    "mu = diversity_series.mean()\n",
    "sigma = diversity_series.std()\n",
    "n = len(diversity_series)\n",
    "\n",
    "print mu, sigma\n",
    "\n",
    "min_ci_90 = mu - 1.64*(mu*(1-mu)/n)**.5\n",
    "print min_ci_90\n",
    "#funny that the score comes in just below the confidence interval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output to the worker table in the db\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
