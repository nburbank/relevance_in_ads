{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from datetime import datetime, date, time, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'_unit_id', u'_created_at', u'_golden', u'_id',\n",
       "       u'_missed', u'_started_at', u'_tainted', u'_channel', u'_trust',\n",
       "       u'_worker_id', u'_country', u'_region', u'_city', u'_ip',\n",
       "       u'please_make_your_relevancy_judgment', u'orig__created_at',\n",
       "       u'orig__golden', u'orig__unit_id', u'_updated_at', u'endurl', u'nil',\n",
       "       u'please_make_your_relevancy_judgment_gold',\n",
       "       u'please_make_your_relevancy_judgment_gold_reason', u'query',\n",
       "       u'starturl', u'type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "raw_df = pd.read_csv('cleaned_urx_data.csv')\n",
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### manipulation of data\n",
    "\n",
    "# dict of created times and ids\n",
    "created_at_dict = dict()\n",
    "for line in raw_df.groupby('_worker_id')['_created_at']:\n",
    "    created_at_dict[line[0]] = line[1]\n",
    "    \n",
    "# dict of started times and ids    \n",
    "started_at_dict = dict()\n",
    "for line in raw_df.groupby('_worker_id')['_started_at']:\n",
    "    started_at_dict[line[0]] = line[1]\n",
    "    \n",
    "# dict of scores and ids\n",
    "scores_dict = dict()\n",
    "for line in raw_df.groupby('_worker_id')['please_make_your_relevancy_judgment']:\n",
    "    scores_dict[line[0]] = list(line[1]) #coerce to list bc i hate indexing on the series\n",
    "    \n",
    "# dict of trust and ids\n",
    "trust_dict = dict()\n",
    "for line in raw_df.groupby('_worker_id'):\n",
    "    trust_dict[line[0]] = line[1]['_trust'][line[1]['_trust'].keys()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## identify diversity in job creation, job start time differences  \n",
    "\n",
    "# takes a list of datetime strings and returns a list of datetime objects\n",
    "def make_list_datetime(list_of_time_strings):\n",
    "    date_time_list = []\n",
    "    for time in list_of_time_strings:\n",
    "        date_time_list.append(datetime.strptime(time, \"%m/%d/%Y %H:%M:%S\"))\n",
    "    return date_time_list\n",
    "\n",
    "\n",
    "# take in lists of creation, start datetime strings, output list of differences in seconds \n",
    "def creation_start_dif(creation_list, start_list):\n",
    "    # make all into datetime objects \n",
    "    creation_datetimes = make_list_datetime(creation_list)\n",
    "    start_datetimes = make_list_datetime(start_list)\n",
    "    \n",
    "    # iterate through to calculate each difference \n",
    "    creation_start_diffs = []\n",
    "    indexer = range(0,len(creation_datetimes))\n",
    "    for index in indexer:\n",
    "        diff = creation_datetimes[index] - start_datetimes[index]\n",
    "        creation_start_diffs.append(diff.total_seconds())    \n",
    "    return creation_start_diffs\n",
    "\n",
    "\n",
    "def get_diversity_score(created_dict, started_dict ):\n",
    "\n",
    "    # produce the list of differences for each worker \n",
    "    creation_time = created_dict.values()\n",
    "    started_time = started_dict.values()\n",
    "    \n",
    "    creation_start_diff_list = []\n",
    "    indexer = range(0,len(started_time))\n",
    "    for index in indexer:\n",
    "        diff_list = creation_start_dif(creation_time[index], started_time[index])\n",
    "        creation_start_diff_list.append(diff_list)\n",
    "    \n",
    "    # calculate the diversity measure\n",
    "    diversity_list = []\n",
    "\n",
    "    for ind_list in creation_start_diff_list:\n",
    "        uniques = len(set(ind_list)) + 0.0\n",
    "        diversity = uniques/len(ind_list)\n",
    "        diversity_list.append(diversity)\n",
    "    \n",
    "        \n",
    "    return diversity_list\n",
    "\n",
    "diversity_scores = get_diversity_score(created_at_dict, started_at_dict)\n",
    "\n",
    "too_little_diversity = []\n",
    "for diversity_score in diversity_scores:\n",
    "    too_little_diversity.append(int(diversity_score < .08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get job counts, variance, and mean for each worker \n",
    "worker_job_count = []\n",
    "worker_variance = []\n",
    "worker_mean = []\n",
    "for worker in scores_dict.values():\n",
    "    worker_job_count.append(len(worker))\n",
    "    worker_variance.append(np.var(worker))\n",
    "    worker_mean.append(np.mean(worker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ## judge the job counts and variance  \n",
    "too_many_jobs = []\n",
    "too_little_variance = []\n",
    "\n",
    "indexer = range(0, len(worker_job_count))\n",
    "for index in indexer:\n",
    "    too_many_jobs.append(int(worker_job_count[index] > 150))\n",
    "    too_little_variance.append(int(worker_variance[index] < .2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## judge the average \n",
    "##\n",
    "\n",
    "all_scores = raw_df['please_make_your_relevancy_judgment']\n",
    "\n",
    "subtract = min(all_scores)\n",
    "norm_scores = all_scores - min(all_scores)\n",
    "divide_by = max(norm_scores)\n",
    "norm_scores = all_scores / max(norm_scores)\n",
    "\n",
    "\n",
    "true_mu = np.mean(norm_scores) + 0.0\n",
    "\n",
    "low_ci = []\n",
    "high_ci = []\n",
    "\n",
    "for scores in scores_dict.values():\n",
    "    # normalize \n",
    "    scores = scores - subtract\n",
    "    scores = scores / divide_by\n",
    "    \n",
    "    mu = np.mean(scores)\n",
    "    z = 1.96\n",
    "    other_part = (true_mu)*(1-true_mu)/len(scores)\n",
    "    other_part = other_part ** .5\n",
    "    low_ci_val = mu - z*other_part\n",
    "    high_ci_val = mu + z*other_part\n",
    "    low_ci.append(low_ci_val)\n",
    "    high_ci.append(high_ci_val)\n",
    "\n",
    "\n",
    "normalized_worker_mean = []\n",
    "\n",
    "for mean in worker_mean:\n",
    "    new_mean = mean - subtract\n",
    "    new_mean = new_mean / divide_by\n",
    "    normalized_worker_mean.append(new_mean)\n",
    "    \n",
    "unreasonable_mean = []\n",
    "    \n",
    "# is the average unreasoanble? \n",
    "indexer = range(0, len(worker_mean))\n",
    "for index in indexer:\n",
    "    if normalized_worker_mean[index] > high_ci[index]:\n",
    "        unreasonable_mean.append(1)\n",
    "    elif normalized_worker_mean[index] < low_ci[index]:\n",
    "        unreasonable_mean.append(1)\n",
    "    else:\n",
    "        unreasonable_mean.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "worker_df = pd.DataFrame()\n",
    "worker_df['_worker_id'] = created_at_dict.keys()\n",
    "worker_df['too_many_jobs'] = too_many_jobs\n",
    "worker_df['too_little_variance'] = too_little_variance\n",
    "worker_df['unreasonable_mean'] = unreasonable_mean\n",
    "worker_df['suspicious_timestamps'] = too_little_diversity\n",
    "worker_df['_trust'] = trust_dict.values()\n",
    "worker_df['agg_score'] = worker_df.ix[:, worker_df.columns != '_worker_id'].apply(sum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 12 out of 80 total workers\n"
     ]
    }
   ],
   "source": [
    "# although i do this later, ti's good to see these things here  \n",
    "\n",
    "workers = worker_df\n",
    "# identify humans vs. robots \n",
    "humans = workers['agg_score'].apply(lambda x: x < 2)\n",
    "robots = 1-humans\n",
    "human_ids = workers['_worker_id'][humans]\n",
    "robot_ids = workers['_worker_id'][robots]\n",
    "print \"there are \" + str(sum(robots)) + \" out of \" + str(len(robots)) + \" total workers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this eliminates 2831 out of 9058 original scores\n"
     ]
    }
   ],
   "source": [
    "# remove the scores attributable to robots \n",
    "human_rows = raw_df['_worker_id'].apply(lambda x: x in set(human_ids))\n",
    "humans_only = raw_df[human_rows]\n",
    "\n",
    "print \"this eliminates \" + str(len(raw_df) - len(humans_only)) + \" out of \" + str(len(raw_df)) + \" original scores\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output to the worker table in the db\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# need libraries for conneting with databse \n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "\n",
    "# create sql engine\n",
    "dbname = 'urx'\n",
    "username = 'noahburbank'\n",
    "engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upload to the database\n",
    "worker_df.to_sql('worker_table', engine, if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
